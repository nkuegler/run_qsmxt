# run_qsmxt
A repository to QSMxT for a batch of subject/sessions


> **Important hint: QSMxT seems to not run on the SLURM node drachenkopf (probably due to incompatibility of the QSMxT container and the installed EPYC CPU). This node is therefore excluded in the sbatch command using the -x flag!**

## How to run 

- adjust properties of the qsmxt command in `qsmxt_slurm.sh`

```
getserver -sb

cd /path/to/output/dir
# before the qsmxt command is executed, the singularity container is made available by sourcing `bash.singularity` (custom file) and the correct conda environment is activated after sourcing `bash.conda` (custom file)

/data/u_kuegler_software/git/qsm/run_qsmxt/call_qsmxt_n.sh input_dir output_dir sub-001 sub-002 sub-003
```

> Note: it is important to specify the session's name, not only the subject's name. Otherwise, the execution of `call_qsmxt.sh` raises an error in the romeo_combine_phase step *(this only works if there are no session directories in the subject directory)*.

> Note: These scripts are proprietary, as they require some custom files for making the singularity container and conda available


### Command for IronSleep Data
```
# sbatch on slurm
./call_qsmxt_n.sh --seq /data/pt_02262/data/TH_bids/bids/derivatives/LORAKS_LCPCA_distCorr/ /data/pt_02262/data/TH_bids/bids/derivatives/LORAKS_LCPCA_distCorr_QSMxT/20250714_qsmxt_pdf/ sub-001

# not slurm:
qsmxt /data/pt_02262/data/TH_bids/bids/derivatives/LORAKS_LCPCA_distCorr/ \
    /data/pt_02262/data/TH_bids/bids/derivatives/LORAKS_LCPCA_distCorr_QSMxT/20250714_qsmxt_pdf/ \
    --premade 'gre' \
    --do_qsm \
    --do_swi \
    --labels_file '/data/u_kuegler_software/miniforge3/envs/qsmxt8/lib/python3.8/site-packages/qsmxt/aseg_labels.csv' \
    --recs rec-loraksRsos \  
    --acqs acq-T1w acq-PDw acq-MTw \  
    --bf_algorithm 'pdf' \
    --auto_yes
```

## Brain Extraction with SynthStrip

The repository includes scripts for batch brain extraction using FreeSurfer's `mri_synthstrip`.

### Usage

```bash
./call_synthstrip.sh [--acqs <ACQ_TYPES>] [--no-csf] [--holefill <ITERATIONS>] [--separate-masks] <INPUT_DIR> <OUTPUT_DIR> <SUBJECT1> [SUBJECT2] ...
```

**Options:**
- `--acqs <ACQ_TYPES>` - Comma-separated acquisition types (default: `PDw,T1w,MTw`)
- `--no-csf` - Exclude CSF from brain mask
- `--holefill <ITERATIONS>` - Enable mask hole-filling with specified dilation/erosion iterations
- `--separate-masks` - Create separate brain masks for each acquisition type (see below)

**Features:**
- **Shared brain mask mode (default):** Only the reference contrast (T1w by default) is processed with `mri_synthstrip`. For other acquisition types (PDw, MTw), symbolic links are created pointing to the reference mask, and brain-extracted images are generated by applying the reference mask. The reason for this approach is that PDw and MTw images typically provide lower quality brain masks than T1w. 
> **WARNING:** There may be a slight misregistration between T1w and other contrasts as they are acquired by separate sequences. No explicit co-registration is performed here. Keep in mind that the mask may not perfectly align on all contrasts. Use the separate masks mode if your the brains are not well aligned across contrasts.
- **Separate masks mode** (`--separate-masks`): Each acquisition type is processed independently with `mri_synthstrip`, creating unique masks for each contrast.
- **Configurable reference contrast:** The reference contrast used for shared masks can be changed by modifying `REF_BRAIN_MASK_CONTRAST` in `synthstrip_slurm.sh` (default: `T1w`).
- Automatically discovers sessions with anatomical data
- Processes multiple acquisition types (PDw, T1w, MTw)
- Matches files with `echo-01` or `echo-1` naming conventions
- GPU acceleration (auto-detected)
- Generates both brain-extracted images (`_brain.nii`) and masks (`_mask.nii`)
- **Saves execution command** to `synthstrip_command.txt` in the output directory for reproducibility
- **Optional morphological hole-filling** of masks using FSL's fslmaths:
  - Performed directly within the same SLURM job after mask creation
  - Uses successive dilation and erosion operations (configurable number of iterations)
  - Overwrites original mask with filled version
  - Re-applies filled mask to input image, updating `_brain.nii` output
- Parallel job submission by default
- Warning when multiple matching files found per acquisition type (processes all)

### Examples

```bash
# Process all subjects with default acquisition types (shared T1w mask mode)
./call_synthstrip.sh /path/to/input /path/to/output sub-001 sub-002 sub-003

# Custom acquisition types with CSF exclusion
./call_synthstrip.sh --acqs PDw,T1w --no-csf /path/to/input /path/to/output sub-001 sub-002

# With hole-filling (7 iterations)
./call_synthstrip.sh --holefill 7 /path/to/input /path/to/output sub-001 sub-002

# Separate masks mode - create unique mask for each acquisition type
./call_synthstrip.sh --separate-masks /path/to/input /path/to/output sub-001 sub-002

# Combine multiple options
./call_synthstrip.sh --acqs PDw,T1w --no-csf --holefill 5 /path/to/input /path/to/output sub-001

# IronSleep data example
./call_synthstrip.sh \
  /data/pt_02262/data/TH_bids/bids/derivatives/LORAKS_LCPCA_distCorr \
  /data/pt_02262/data/TH_bids/bids/derivatives/LORAKS_LCPCA_distCorr/derivatives/synthstrip \
  sub-001 sub-002
```

> **Note:** Default approach: only T1w images are processed with `mri_synthstrip`, and symbolic links are created for PDw/MTw masks pointing to the T1w mask. This ensures consistent brain extraction across all contrasts. Use `--separate-masks` if you need independent masks for each acquisition type. The reference contrast can be changed by editing `REF_BRAIN_MASK_CONTRAST` in `synthstrip_slurm.sh`.

> **Note:** SynthStrip works on all SLURM nodes (no node exclusions needed). When hole-filling is enabled, the original `_mask.nii` file is overwritten with the filled version, and the `_brain.nii` file is regenerated using the filled mask.


# Example synthstrip

```
subjs=$(find /data/pt_02262/data/liege_data/bids/derivatives/LORAKS/derivatives/LCPCA_distCorr/ -maxdepth 1 -type d -name 'sub-*' -exec basename {} \; | sort -V | tr '\n' ' ')

./call_synthstrip.sh --no-csf --holefill 7 /data/pt_02262/data/liege_data/bids/derivatives/LORAKS/derivatives/LCPCA_distCorr/ /data/pt_02262/data/liege_data/bids/derivatives/LORAKS/derivatives/LCPCA_distCorr/derivatives/synthstrip/ $subjs

./call_qsmxt_n.sh --transform-to-orig /data/pt_02262/data/liege_data/bids/derivatives/LORAKS/derivatives/LCPCA_distCorr/ /data/pt_02262/data/liege_data/bids/derivatives/LORAKS/derivatives/QSMxT/20251228_qsmxt_pdf_synthstripFilled/ $subjs 
```

## Spatial Transformations

The repository includes scripts for transforming QSMxT outputs to different spatial reference frames.

### Transform to Original Space

Transform QSMxT outputs back to the original input acquisition space using `deprecated_transform_to_orig.sh` or the `--transform-to-orig` flag in `call_qsmxt_n.sh`.

**Integrated workflow (recommended):**
```bash
# Transform outputs during QSMxT processing
./call_qsmxt_n.sh --transform-to-orig <INPUT_DIR> <OUTPUT_DIR> <SUBJECTS...>
```

**Standalone script:**
```bash
# Transform already processed outputs
./deprecated_transform_to_orig.sh <QSMXT_OUTPUT_DIR> <ORIGINAL_INPUT_DIR>
```

Creates `transform_to_orig/` subdirectories containing outputs aligned to original acquisition space. Uses FSL flirt with sform-based transformation.

### Transform to MPM Space

Transform Chimap outputs to co-registered MPM reference space using `deprecated_transform_to_mpm.sh`. This aligns QSMxT-derived Chimaps with acquisitions that have been co-registered to PDw space via SPM.

```bash
./deprecated_transform_to_mpm.sh <QSMXT_OUTPUT_DIR> <MPM_REFERENCE_DIR>
```

Creates `transform_to_mpm/` subdirectories with T1w and MTw Chimaps aligned to their corresponding co-registered references. Uses FSL flirt with spline interpolation.

> **Note:** The `transform_to_orig` functionality is integrated into `qsmxt_slurm_n.sh` via the `--transform-to-orig` flag. The `deprecated_transform_to_mpm.sh` script is currently standalone but may be integrated as a separate SLURM job in future versions (see following note for concerns).


> **Note:** The transformation to the mpm space using the original coregistrations of the hMRI toolbox (from MPMCalc directory) turned out to be problematic as the resulting sforms/qforms of the T1w and MTw Chimaps differ from the PDw Chimap (MPM reference space). This makes it more difficult to process and inspect them further. 
> To avoid this, I instead run a separate rigid-body registration using SPM to align the T1w and MTw Chimaps to the PDw Chimap (see `call_coreg_toPDw.sh`)."

## Chimap Coregistration and Averaging

The repository includes scripts for coregistering multi-contrast Chimaps (magnetic susceptibility maps) to a common reference space and averaging them to improve SNR.

### Workflow

**Usage:**
```bash
./call_coreg_toPDw.sh <INPUT_DIR>
```

**What it does:**
1. For each subject/session, identifies T1w, MTw, and PDw Chimaps in `transform_to_orig/` subdirectories
2. Submits SLURM jobs to coregister T1w and MTw Chimaps to PDw Chimap space using SPM12 rigid body transformation
3. Automatically submits a dependent averaging job that:
   - Merges the three coregistered Chimaps (PDw reference + coregistered T1w + coregistered MTw) using FSL `fslmerge`
   - Computes the temporal mean across the three volumes using FSL `fslmaths`
   - Outputs both the merged 4D volume and the averaged 3D volume

**Output files** (saved in `sub-XXX/ses-XX/anat/coreg_toPDw/`):
- `coreg_sub-XXX_ses-XX_acq-T1w_*_MPM_Chimap.nii` - Coregistered T1w Chimap
- `coreg_sub-XXX_ses-XX_acq-MTw_*_MPM_Chimap.nii` - Coregistered MTw Chimap
- `sub-XXX_ses-XX_merged_Chimap.nii` - Concatenated 4D volume of all three Chimaps
- `sub-XXX_ses-XX_mean_Chimap.nii` - Averaged Chimap with improved SNR

**Example:**
```bash
./call_coreg_toPDw.sh /data/pt_02262/data/TH_bids/bids/derivatives/LORAKS/derivatives/QSMxT/20260202_pdf_phaseMask2/
```

**Job dependencies:** The averaging job (`average_chimaps_slurm.sh`) only runs after both coregistration jobs complete successfully, ensuring all required files exist before averaging.

# ToDo

- Implement option to clean up the supplementary directory at the end of each job (and a final clean-up at the end of all jobs)
- (not sure) Integrate `transform_to_mpm.sh` into the SLURM workflow as a separate job -> maybe rather integrate the second SPM registration
- When using shared masks (T1w to PDw/MTw) estimate the registration from T1w to the other contrasts and rotate the mask accordingly before applying it.
- Implement flag to use existing masks. When set, the name of the masking pipeline must be specified (`--existing-masks synthstrip`).
- Implement flag to automatically delete supplementary directory after processing.